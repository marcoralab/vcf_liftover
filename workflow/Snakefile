import os
import stat
import re
import pandas as pd
import numpy as np


def parse_chrom(chrs):
    clist = [x.split(":") for x in chrs.split(",")]
    parsed = []
    for chrs in clist:
        if len(chrs) == 2:
            chrs = [str(c) for c in range(int(chrs[0]), int(chrs[1]) + 1)]
        elif len(chrs) != 1:
            raise ValueError("Invalid chromosome list.")
        parsed += chrs
    return parsed


include: 'ref.smk'

configfile: "config/config.yaml"
if ('inputs' in config):
    inputs = config['inputs']
else:
    raise KeyError("inputs are missing in config.yaml")

inputs = pd.DataFrame.from_dict(inputs, orient='index')

GATK_BUILDS_ONLY = config['all_GATK_builds']

def calculate_build(in_build):
    if in_build.lower() in ['grch36', 'b36', 'ncbi36', 'hg18']:
        return 36
    elif in_build.lower() in ['grch37', 'b37', 'hg19', 'humang1kv37']:
        return 37
    elif in_build.lower() in ['grch38', 'b38', 'hg38']:
        return 38

def fillcol(df, colname, default):
    if colname not in df:
        df[colname] = default
        return df
    df[colname] = df[colname].fillna(default)
    return df


output_builds = {calculate_build(x) for x in config['output_builds']}

inputs = fillcol(inputs, 'output', '_rplc_')
inputs = fillcol(inputs, 'filter', '_none_')
inputs = fillcol(inputs, 'contigs', '1:22')
inputs['build_no_start'] = [calculate_build(x) for x in inputs['build']]
inputs['contigs'] = [parse_chrom(x) for x in inputs['contigs']]


localrules: all

chbs = lambda: zip(inputs.index.to_list(),
                   inputs['build_no_start'].to_list(),
                   inputs['contigs'].to_list())


def filter_mainchrs(chrlist):
  chrset = set(chrlist) & set(parse_chrom('1:22,X,Y,MT'))
  chrlist = [*chrset]
  chrlist.sort()
  return chrlist


def liftbuilds(tmplt, cht, startbuild):
  builds = output_builds - {startbuild}
  return expand(tmplt, cohort=cht, tobuild=builds)


def liftbuilds_chr(tmplt, cht, startbuild, chr):
  builds = output_builds - {startbuild}
  chr_ = filter_mainchrs(chr)
  return expand(tmplt, cohort=cht, chrom=chr_, tobuild=builds)


def flatten(l):
  return sum(map(flatten,l),[]) if isinstance(l,list) else [l]


mismatched = 'output/{cohort}.b{tobuild}.mismatched_chroms.vcf.gz'
mismatched = flatten([liftbuilds(mismatched, x, y) for x, y, z in chbs()])

matched = 'output/{cohort}.b{tobuild}.chr{chrom}_only.vcf.gz'
matched = flatten([liftbuilds_chr(matched, x, y, z) for x, y, z in chbs()])

matched_allchr = 'output/{cohort}.b{tobuild}.same_chr.vcf.gz'
matched_allchr = flatten([liftbuilds(matched_allchr, x, y) for x, y, z in chbs()])

if config['concatenate']:
  matched = matched_allchr

b37file = 'data/ref/b37.builds.tsv'
b37_contigs = flatten(pd.read_csv(b37file, sep='\t').values.tolist())
constraint_exclude = {'chr' + x for x in parse_chrom('1:22,X,Y,M')}
b37_contigs_excl = set(b37_contigs) - constraint_exclude
b37_contigs_excl = '|'.join([*b37_contigs_excl])

wildcard_constraints:
  chrom=b37_contigs_excl


rule all:
  input:
    mismatched,
    matched



def getstartfile(wildcards):
  return inputs.loc[wildcards.cohort, 'input_vcf']

def chromname_in(wc):
  hg19 = wc.frombuild.lower() in ['grch37', 'hg19'] and not GATK_BUILDS_ONLY
  if hg19 or int(re.findall(r'\d+', wc.frombuild)[-1]) == 38:
    if wc.chrom in parse_chrom('1:22,X,Y'):
      return 'chr{}'.format(wc.chrom)
    if wc.chrom == "MT":
      return 'chrM'
  return wc.chrom


rule split_chrom:
  input: getstartfile
  output:
    vcf = temp('temp/{cohort}.{frombuild}.chr{chrom}.SPLIT.vcf.gz'),
    tbi = temp('temp/{cohort}.{frombuild}.chr{chrom}.SPLIT.vcf.gz.tbi')
  params:
    chr = chromname_in
  conda: 'envs/hgdpenv.yaml'
  shell: '''
if [ ! -f {input}.tbi ]; then
  bcftools index -t {input}
fi
bcftools view --regions {params.chr} {input} -Oz -o {output.vcf}
bcftools index -t {output.vcf}
'''


def gsfi(wildcards):
  sf = getstartfile(wildcards)
  if '{chrom}' in sf:
    return sf
  return rules.split_chrom.output.vcf


rule filter:
  input: gsfi
  output:
    vcf = temp('temp/{cohort}.{frombuild}.chr{chrom}.FILTERED.vcf.gz'),
    tbi = temp('temp/{cohort}.{frombuild}.chr{chrom}.FILTERED.vcf.gz.tbi')
  params:
    filter = lambda wildcards: inputs.loc[wildcards.cohort, 'filter']
  conda: 'envs/hgdpenv.yaml'
  shell: '''
if [ ! -f {input}.tbi ]; then
  bcftools index -t {input}
fi
bcftools view -f {params.filter} {input} -Oz -o {output.vcf}
bcftools index -t {output.vcf}
'''


rule nofilter:
  input: gsfi
  output:
    vcf = temp('temp/{cohort}.{frombuild}.chr{chrom}.UNFILTERED.vcf.gz'),
    tbi = temp('temp/{cohort}.{frombuild}.chr{chrom}.UNFILTERED.vcf.gz.tbi')
  conda: 'envs/hgdpenv.yaml'
  shell: '''
cp {input} {output.vcf}
bcftools index -t {output.vcf}
'''

gatk = 'docker://broadinstitute/gatk:4.1.8.1'

def lift_input(wildcards):
  if inputs.loc[wildcards.cohort, 'filter'] == '_none_':
    return rules.nofilter.output.vcf
  return rules.filter.output.vcf

rule liftover:
  input:
    vcf = lift_input,
    chain = 'data/ref/{frombuild}_to_b{tobuild}.over.chain.gz',
    fasta = 'data/ref/b{tobuild}.fa.gz',
    fdict = 'data/ref/b{tobuild}.dict'
  output:
    vcf = temp('temp/{cohort}.from-{frombuild}_to-b{tobuild}.chr{chrom}.vcf.gz'),
    tbi = temp('temp/{cohort}.from-{frombuild}_to-b{tobuild}.chr{chrom}.vcf.gz.tbi'),
    rejects = 'output/rejects/{cohort}.from-{frombuild}_to-b{tobuild}.chr{chrom}.rejects.vcf.gz'
  params:
    tempdir = 'temp/liftOver/{cohort}.from-{frombuild}_to-b{tobuild}.chr{chrom}'
  container: gatk
  log: 'logs/{cohort}.from-{frombuild}_to-b{tobuild}.chr{chrom}.liftover.log'
  shell: '''
mkdir -p {params.tempdir}
gatk LiftoverVcf \
 --I {input.vcf} --O {output.vcf} --CHAIN {input.chain} --R {input.fasta} \
 --REJECT {output.rejects} --TMP_DIR {params.tempdir} \
 --MAX_RECORDS_IN_RAM 50000 &> {log}
'''

def chromname(wildcards):
  if int(re.findall(r'\d+', wildcards.tobuild)[-1]) == 38:
    if wildcards.chrom == 'MT':
      return 'chrM'
    return 'chr{}'.format(wildcards.chrom)
  return wildcards.chrom

def get_out(wc):
  return inputs.loc[wildcards.cohort, 'output']


def matched_in_vcf(wildcards):
  fbuild = inputs.loc[wildcards.cohort, 'build']
  if GATK_BUILDS_ONLY:
    fbuild = 'b' + str(calculate_build(fbuild))
  string_ = 'temp/{{cohort}}.from-{frombuild}_to-b{{tobuild}}.chr{{chrom}}.vcf.gz'
  return expand(string_, frombuild=fbuild)


def matched_in_tbi(wildcards):
  fbuild = inputs.loc[wildcards.cohort, 'build']
  if GATK_BUILDS_ONLY:
    fbuild = 'b' + str(calculate_build(fbuild))
  string_ = 'temp/{{cohort}}.from-{frombuild}_to-b{{tobuild}}.chr{{chrom}}.vcf.gz.tbi'
  return expand(string_, frombuild=fbuild)


rule keep_chrom:
  input:
    vcf = matched_in_vcf,
    tbi = matched_in_tbi
  params:
    chrom = chromname
  output:
    vcf = 'output/{cohort}.b{tobuild}.chr{chrom}_only.vcf.gz',
    tbi = 'output/{cohort}.b{tobuild}.chr{chrom}_only.vcf.gz.tbi'
  conda: 'envs/hgdpenv.yaml'
  shell: '''
bcftools view -t {params.chrom} -Oz -o {output.vcf} {input.vcf}
bcftools index -t {output.vcf}
'''

rule separate_chrom:
  input:
    vcf = rules.liftover.output.vcf,
    tbi = rules.liftover.output.tbi
  params:
    chrom = chromname
  output:
    vcf = temp('temp/{cohort}.from-{frombuild}_to-b{tobuild}.chr{chrom}_different.vcf.gz'),
    tbi = temp('temp/{cohort}.from-{frombuild}_to-b{tobuild}.chr{chrom}_different.vcf.gz.tbi'),
  conda: 'envs/hgdpenv.yaml'
  shell: '''
bcftools view -t ^{params.chrom} -Oz -o {output.vcf} {input.vcf}
bcftools index -t {output.vcf}
'''


def mismatched_in_vcf(wildcards):
  fbuild = inputs.loc[wildcards.cohort, 'build']
  if GATK_BUILDS_ONLY:
    fbuild = 'b' + str(calculate_build(fbuild))
  string_ = 'temp/{{cohort}}.from-{frombuild}_to-b{{tobuild}}.chr{chrom}_different.vcf.gz'
  chrs = inputs.loc[wildcards.cohort, 'contigs']
  return expand(string_, frombuild=fbuild, chrom=chrs)


def mismatched_in_tbi(wildcards):
  fbuild = inputs.loc[wildcards.cohort, 'build']
  if GATK_BUILDS_ONLY:
    fbuild = 'b' + str(calculate_build(fbuild))
  string_ = 'temp/{{cohort}}.from-{frombuild}_to-b{{tobuild}}.chr{chrom}_different.vcf.gz.tbi'
  chrs = inputs.loc[wildcards.cohort, 'contigs']
  return expand(string_, frombuild=fbuild, chrom=chrs)

rule separate_chrom_combine:
  input:
    vcf = mismatched_in_vcf,
    tbi = mismatched_in_tbi
  output:
    vcf = 'output/{cohort}.b{tobuild}.mismatched_chroms.vcf.gz',
    tbi = 'output/{cohort}.b{tobuild}.mismatched_chroms.vcf.gz.tbi'
  conda: 'envs/hgdpenv.yaml'
  shell: '''
bcftools concat -a -Oz -o {output.vcf} {input.vcf}
bcftools index -t {output.vcf}
'''


def same_in_vcf(wildcards):
  string_ = 'output/{{cohort}}.b{{tobuild}}.chr{chrom}_only.vcf.gz'
  chrs = filter_mainchrs(inputs.loc[wildcards.cohort, 'contigs'])
  return expand(string_, chrom=chrs)


def same_in_tbi(wildcards):
  string_ = 'output/{{cohort}}.b{{tobuild}}.chr{chrom}_only.vcf.gz.tbi'
  chrs = filter_mainchrs(inputs.loc[wildcards.cohort, 'contigs'])
  return expand(string_, chrom=chrs)

rule same_chrom_combine:
  input:
    vcf = same_in_vcf,
    tbi = same_in_tbi
  output:
    vcf = 'output/{cohort}.b{tobuild}.same_chr.vcf.gz',
    tbi = 'output/{cohort}.b{tobuild}.same_chr.vcf.gz.tbi'
  conda: 'envs/hgdpenv.yaml'
  shell: '''
bcftools concat -a -Oz -o {output.vcf} {input.vcf}
bcftools index -t {output.vcf}
'''
